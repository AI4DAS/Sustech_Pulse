{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 震相拾取与记分流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zbk/anaconda3/envs/ditinglsm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/zbk/anaconda3/envs/ditinglsm/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please 'pip install apex'\n",
      "=> loading checkpoint '/home/disk/wd_black/wzm/Sustech_Pulse/model/DiTing/DiTing0.1B-preview/DiTing0.1B-preview.pth'\n",
      "[linear_probe/none]Trainable parameters: 13613663\n",
      "[linear_probe/none]Trainable parameters: 23279007\n",
      "Sequential(\n",
      "  (0): ViTAdapter(\n",
      "    (backbone): PatchTSTEncoder(\n",
      "      (W_p): Conv1d(3, 512, kernel_size=(50,), stride=(50,))\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (encoder): TSTEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-23): 24 x TSTEncoderLayer(\n",
      "            (self_attn): MultiheadAttention_ROPE(\n",
      "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (o_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "              (sdp_attn): ScaledDotProductAttention(\n",
      "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (norm_attn): LlamaRMSNorm()\n",
      "            (gate_proj): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (up_proj): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (down_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (act_fn): SiLU()\n",
      "            (drop_path2): Identity()\n",
      "            (norm_ffn): LlamaRMSNorm()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (encoder_norm): LlamaRMSNorm()\n",
      "    )\n",
      "    (spm): SpatialPriorModule(\n",
      "      (stem): Sequential(\n",
      "        (0): Conv1d(3, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "        (1): LayerNorm()\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "        (4): LayerNorm()\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "        (7): LayerNorm()\n",
      "        (8): ReLU(inplace=True)\n",
      "        (9): AdaptiveMaxPool1d(output_size=800)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "        (1): LayerNorm()\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "        (1): LayerNorm()\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv4): Sequential(\n",
      "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "        (1): LayerNorm()\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (fc2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
      "      (fc3): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "      (fc4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (interactions): Sequential(\n",
      "      (0): InteractionBlock(\n",
      "        (injector): Injector(\n",
      "          (cpe_q): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (cpe_k): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (query_norm): LayerNorm()\n",
      "          (feat_norm): LayerNorm()\n",
      "          (attn): PS_Attention(\n",
      "            (qkv): ModuleList(\n",
      "              (0-2): 3 x Depthwise_Separable_Conv(\n",
      "                (dw): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "                (norm): LayerNorm()\n",
      "                (pw): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "            )\n",
      "            (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "            (proj_drop): Identity()\n",
      "            (attn_drop): Identity()\n",
      "          )\n",
      "        )\n",
      "        (extractor): Extractor(\n",
      "          (cpe_q): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (cpe_k): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (query_norm): LayerNorm()\n",
      "          (feat_norm): LayerNorm()\n",
      "          (attn): PS_Attention(\n",
      "            (qkv): ModuleList(\n",
      "              (0-2): 3 x Depthwise_Separable_Conv(\n",
      "                (dw): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "                (norm): LayerNorm()\n",
      "                (pw): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "            )\n",
      "            (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "            (proj_drop): Identity()\n",
      "            (attn_drop): Identity()\n",
      "          )\n",
      "          (ffn): ConvFFN(\n",
      "            (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dwconv): DWConv(\n",
      "              (dwconv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (drop): Identity()\n",
      "          )\n",
      "          (ffn_norm): LayerNorm()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): InteractionBlock(\n",
      "        (injector): Injector(\n",
      "          (cpe_q): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (cpe_k): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (query_norm): LayerNorm()\n",
      "          (feat_norm): LayerNorm()\n",
      "          (attn): PS_Attention(\n",
      "            (qkv): ModuleList(\n",
      "              (0-2): 3 x Depthwise_Separable_Conv(\n",
      "                (dw): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "                (norm): LayerNorm()\n",
      "                (pw): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "            )\n",
      "            (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "            (proj_drop): Identity()\n",
      "            (attn_drop): Identity()\n",
      "          )\n",
      "        )\n",
      "        (extractor): Extractor(\n",
      "          (cpe_q): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (cpe_k): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (query_norm): LayerNorm()\n",
      "          (feat_norm): LayerNorm()\n",
      "          (attn): PS_Attention(\n",
      "            (qkv): ModuleList(\n",
      "              (0-2): 3 x Depthwise_Separable_Conv(\n",
      "                (dw): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "                (norm): LayerNorm()\n",
      "                (pw): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "            )\n",
      "            (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "            (proj_drop): Identity()\n",
      "            (attn_drop): Identity()\n",
      "          )\n",
      "          (ffn): ConvFFN(\n",
      "            (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dwconv): DWConv(\n",
      "              (dwconv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (drop): Identity()\n",
      "          )\n",
      "          (ffn_norm): LayerNorm()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): InteractionBlock(\n",
      "        (injector): Injector(\n",
      "          (cpe_q): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (cpe_k): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (query_norm): LayerNorm()\n",
      "          (feat_norm): LayerNorm()\n",
      "          (attn): PS_Attention(\n",
      "            (qkv): ModuleList(\n",
      "              (0-2): 3 x Depthwise_Separable_Conv(\n",
      "                (dw): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "                (norm): LayerNorm()\n",
      "                (pw): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "            )\n",
      "            (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "            (proj_drop): Identity()\n",
      "            (attn_drop): Identity()\n",
      "          )\n",
      "        )\n",
      "        (extractor): Extractor(\n",
      "          (cpe_q): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (cpe_k): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (query_norm): LayerNorm()\n",
      "          (feat_norm): LayerNorm()\n",
      "          (attn): PS_Attention(\n",
      "            (qkv): ModuleList(\n",
      "              (0-2): 3 x Depthwise_Separable_Conv(\n",
      "                (dw): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "                (norm): LayerNorm()\n",
      "                (pw): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "            )\n",
      "            (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "            (proj_drop): Identity()\n",
      "            (attn_drop): Identity()\n",
      "          )\n",
      "          (ffn): ConvFFN(\n",
      "            (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dwconv): DWConv(\n",
      "              (dwconv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (drop): Identity()\n",
      "          )\n",
      "          (ffn_norm): LayerNorm()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): InteractionBlock(\n",
      "        (injector): Injector(\n",
      "          (cpe_q): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (cpe_k): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (query_norm): LayerNorm()\n",
      "          (feat_norm): LayerNorm()\n",
      "          (attn): PS_Attention(\n",
      "            (qkv): ModuleList(\n",
      "              (0-2): 3 x Depthwise_Separable_Conv(\n",
      "                (dw): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "                (norm): LayerNorm()\n",
      "                (pw): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "            )\n",
      "            (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "            (proj_drop): Identity()\n",
      "            (attn_drop): Identity()\n",
      "          )\n",
      "        )\n",
      "        (extractor): Extractor(\n",
      "          (cpe_q): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (cpe_k): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (query_norm): LayerNorm()\n",
      "          (feat_norm): LayerNorm()\n",
      "          (attn): PS_Attention(\n",
      "            (qkv): ModuleList(\n",
      "              (0-2): 3 x Depthwise_Separable_Conv(\n",
      "                (dw): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "                (norm): LayerNorm()\n",
      "                (pw): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "            )\n",
      "            (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "            (proj_drop): Identity()\n",
      "            (attn_drop): Identity()\n",
      "          )\n",
      "          (ffn): ConvFFN(\n",
      "            (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dwconv): DWConv(\n",
      "              (dwconv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (drop): Identity()\n",
      "          )\n",
      "          (ffn_norm): LayerNorm()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): InteractionBlock(\n",
      "        (injector): Injector(\n",
      "          (cpe_q): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (cpe_k): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (query_norm): LayerNorm()\n",
      "          (feat_norm): LayerNorm()\n",
      "          (attn): PS_Attention(\n",
      "            (qkv): ModuleList(\n",
      "              (0-2): 3 x Depthwise_Separable_Conv(\n",
      "                (dw): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "                (norm): LayerNorm()\n",
      "                (pw): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "            )\n",
      "            (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "            (proj_drop): Identity()\n",
      "            (attn_drop): Identity()\n",
      "          )\n",
      "        )\n",
      "        (extractor): Extractor(\n",
      "          (cpe_q): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (cpe_k): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "          (query_norm): LayerNorm()\n",
      "          (feat_norm): LayerNorm()\n",
      "          (attn): PS_Attention(\n",
      "            (qkv): ModuleList(\n",
      "              (0-2): 3 x Depthwise_Separable_Conv(\n",
      "                (dw): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
      "                (norm): LayerNorm()\n",
      "                (pw): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "              )\n",
      "            )\n",
      "            (proj): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "            (proj_drop): Identity()\n",
      "            (attn_drop): Identity()\n",
      "          )\n",
      "          (ffn): ConvFFN(\n",
      "            (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dwconv): DWConv(\n",
      "              (dwconv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=128)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (drop): Identity()\n",
      "          )\n",
      "          (ffn_norm): LayerNorm()\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up_): ConvTranspose1d(512, 512, kernel_size=(2,), stride=(2,))\n",
      "    (down_): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (norm2): LayerNorm()\n",
      "    (norm3): LayerNorm()\n",
      "    (norm4): LayerNorm()\n",
      "  )\n",
      "  (1): MuHead_TaskSeparatedUPerHead_new(\n",
      "    (psp_modules): PPM(\n",
      "      (0): Sequential(\n",
      "        (0): AdaptiveAvgPool1d(output_size=1)\n",
      "        (1): ConvModule(\n",
      "          (conv): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (norm): LayerNorm()\n",
      "          (activate): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): AdaptiveAvgPool1d(output_size=2)\n",
      "        (1): ConvModule(\n",
      "          (conv): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (norm): LayerNorm()\n",
      "          (activate): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): AdaptiveAvgPool1d(output_size=4)\n",
      "        (1): ConvModule(\n",
      "          (conv): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (norm): LayerNorm()\n",
      "          (activate): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): AdaptiveAvgPool1d(output_size=10)\n",
      "        (1): ConvModule(\n",
      "          (conv): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (norm): LayerNorm()\n",
      "          (activate): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bottleneck): ConvModule(\n",
      "      (conv): Conv1d(1536, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (norm): LayerNorm()\n",
      "      (activate): ReLU(inplace=True)\n",
      "    )\n",
      "    (lateral_convs): ModuleList(\n",
      "      (0-1): 2 x ConvModule(\n",
      "        (conv): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (norm): LayerNorm()\n",
      "        (activate): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (fpn_convs): ModuleList(\n",
      "      (0-1): 2 x ConvModule(\n",
      "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "        (norm): LayerNorm()\n",
      "        (activate): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (up_convs): ModuleList(\n",
      "      (0-1): 2 x ConvTranspose1d(256, 256, kernel_size=(2,), stride=(2,))\n",
      "    )\n",
      "    (up_fpn_convs): ModuleList(\n",
      "      (0): Identity()\n",
      "      (1): ConvTranspose1d(256, 256, kernel_size=(2,), stride=(2,))\n",
      "      (2): Sequential(\n",
      "        (0): ConvTranspose1d(256, 256, kernel_size=(2,), stride=(2,))\n",
      "        (1): LayerNorm()\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): ConvTranspose1d(256, 256, kernel_size=(2,), stride=(2,))\n",
      "      )\n",
      "    )\n",
      "    (fpn_bottleneck): ConvModule(\n",
      "      (conv): Conv1d(768, 1280, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "      (norm): LayerNorm()\n",
      "      (activate): ReLU()\n",
      "    )\n",
      "    (act_out): Sigmoid()\n",
      "    (decoder_pred): Linear(in_features=256, out_features=400, bias=True)\n",
      "    (projlast_dpk): Conv1d(3, 3, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (gap): AdaptiveAvgPool1d(output_size=1)\n",
      "    (decoder): PatchTSTDecoder_base(\n",
      "      (decoder_embed): MuReadout(in_features=512, out_features=256, bias=True)\n",
      "      (decoder): TSTEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-3): 4 x TSTEncoderLayer(\n",
      "            (self_attn): MultiheadAttention_ROPE(\n",
      "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (o_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "              (sdp_attn): ScaledDotProductAttention(\n",
      "                (attn_dropout): Dropout(p=0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (norm_attn): LlamaRMSNorm()\n",
      "            (gate_proj): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (up_proj): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (down_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (act_fn): SiLU()\n",
      "            (drop_path2): Identity()\n",
      "            (norm_ffn): LlamaRMSNorm()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder_norm): LlamaRMSNorm()\n",
      "    )\n",
      "    (projlast): Conv1d(3, 3, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (connect_out): Sequential(\n",
      "      (0): ConvTranspose1d(256, 256, kernel_size=(2,), stride=(2,))\n",
      "      (1): ConvModule(\n",
      "        (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "        (norm): LayerNorm()\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (projlast_det): Conv1d(16, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (projlast_ppk): Conv1d(16, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (projlast_spk): Conv1d(16, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  )\n",
      ")\n",
      "############# ckpt keys dict_keys(['epoch', 'optimizer_dict', 'model_dict', 'loss', 'use_compile', 'use_ddp', 'scaler'])\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['1.projlast_dis.weight', '1.projlast_dis.bias', '1.cls_head_dis.weight', '1.cls_head_dis.bias', '1.projlast_emg.weight', '1.projlast_emg.bias', '1.cls_head_emg.weight', '1.cls_head_emg.bias'])\n",
      "=> loaded pre-trained model '/home/disk/wd_black/wzm/Sustech_Pulse/model/DiTing/DiTing0.1B-preview/DiTing0.1B-preview.pth'\n",
      "model has been loaded\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/disk/wd_black/wzm/Sustech_Pulse/model/DiTing/ditingbench_preview\")\n",
    "sys.path.append(\"/home/disk/wd_black/wzm/Sustech_Pulse/src/finetune\")\n",
    "\n",
    "from diting_lsm_model import load_DiTing100M_preveiw #, DiTing_EQDet_PhasePick_predict , DiTing_EQDet_PhasePick_predict_fastV2_multievents , DiTing_EQDet_PhasePick_predict_fastV2\n",
    "from dpk_utils import DiTing_EQDet_PhasePick_predict_fastV2, DiTing_EQDet_PhasePick_predict_fastV2_multievents\n",
    "from diting_all import  DiTing_EQDet_phase_TTA_predict_2 ,DiTing_EQDet_phase_TTA_predict ,DiTing_EQDet_phase_TTA_predict_3\n",
    "\n",
    "from pathlib import Path\n",
    "import obspy\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import torch\n",
    "sys.path.append(\"/home/disk/disk02/wzm/Sustech_Pulse/tutorial/diting_tutorial_001\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dpk_model_path = '/home/disk/wd_black/wzm/Sustech_Pulse/model/DiTing/DiTing0.1B-preview/DiTing0.1B-preview.pth'\n",
    "dpk_device = 'cuda:0'\n",
    "dpk_model = load_DiTing100M_preveiw( weight_path=dpk_model_path, device=dpk_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 记分函数（答案可重复，扣分按整体）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def calculate_score(\n",
    "    P_answer_list: List[float],\n",
    "    S_answer_list: List[float],\n",
    "    P_res_list: List[float],\n",
    "    S_res_list: List[float],\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    计分规则：\n",
    "    - P波：误差<=0.1 记1分；在(0.1, 1]间线性从1降至0；>1 记0分\n",
    "    - S波：误差<=0.2 记1分；在(0.2, 2]间线性从1降至0；>2 记0分\n",
    "    - 匹配策略：遍历“答案”，每次从“结果”中选与该答案最接近的一条进行打分（选过的结果不再复用）\n",
    "    - 惩罚：若结果（预测）数量多于答案数量，超出每一个扣 0.5 分；总分不低于 0\n",
    "    - 最终分数为 P 分 + S 分（分别独立计分与扣分）\n",
    "    \"\"\"\n",
    "    def _err_to_score(err: float, tight: float, loose: float) -> float:\n",
    "        if err <= tight:\n",
    "            return 1.0\n",
    "        if err <= loose:\n",
    "            return 1.0 - (err - tight) / (loose - tight)\n",
    "        return 0.0\n",
    "\n",
    "    def _score_one_phase(answer_list: List[float],\n",
    "                         result_list: List[float],\n",
    "                         tight: float,\n",
    "                         loose: float) -> float:\n",
    "        # 不修改原列表\n",
    "        remaining = sorted(result_list)\n",
    "        total = 0.0\n",
    "        for a in sorted(answer_list):\n",
    "            if not remaining:\n",
    "                # 没有可匹配的结果，记0分，继续\n",
    "                continue\n",
    "            # 找到离当前答案最近的结果并匹配\n",
    "            idx = min(range(len(remaining)), key=lambda i: abs(remaining[i] - a))\n",
    "            err = abs(remaining[idx] - a)\n",
    "            total += _err_to_score(err, tight, loose)\n",
    "            # 该结果已使用，移除，避免复用\n",
    "            #remaining.pop(idx)\n",
    "\n",
    "        # 超检惩罚（仅针对多出来的未被匹配的结果）\n",
    "        extra = len(answer_list) - len(result_list)\n",
    "        if extra < 0:\n",
    "            extra = 0\n",
    "        penalty = 0\n",
    "\n",
    "        return max(0.0, total - penalty)  # 扣到0则不得分\n",
    "\n",
    "    p_score = _score_one_phase(P_answer_list, P_res_list, tight=0.1, loose=1.0)\n",
    "    s_score = _score_one_phase(S_answer_list, S_res_list, tight=0.2, loose=2.0)\n",
    "\n",
    "    return p_score + s_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算主程序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取月份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入月份，自动更改目录\n",
    "month = '09'\n",
    "\n",
    "#数据读取\n",
    "answer_dict = dict()\n",
    "answer_file_path = '/home/disk/wd_black/wzm/Sustech_Pulse/test_data/%s-an/T1.an' %month\n",
    "for line in open(answer_file_path).readlines():\n",
    "    line = line.strip()\n",
    "    key = line.split(':')[0].strip()\n",
    "    P_line = line.split('P :')[1].split(' : S : ')[0]\n",
    "    S_line = line.split(' : S : ')[1]\n",
    "    answer_dict[key] = [P_line, S_line]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zbk/anaconda3/envs/ditinglsm/lib/python3.10/site-packages/obspy/signal/filter.py:62: UserWarning: Selected high corner frequency (50.0) of bandpass is at or above Nyquist (50.0). Applying a high-pass instead.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/wd_black/wzm/Sustech_Pulse/src/finetune/dpk_utils.py:605: RuntimeWarning: invalid value encountered in divide\n",
      "  confidence = confidence / count\n",
      "/home/zbk/anaconda3/envs/ditinglsm/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/zbk/anaconda3/envs/ditinglsm/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 1\n",
      "On 2\n",
      "On 3\n",
      "On 4\n",
      "On 5\n",
      "On 6\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n",
      "T1.E.Q0001.mseed no S\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'calculate_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(out_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     80\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mP_answer_list\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[sta][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_for_compare\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mS_answer_list\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[sta][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS_for_compare\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m p_score,s_score \u001b[38;5;241m=\u001b[39m\u001b[43mcalculate_score\u001b[49m(P_answer_list, S_answer_list, results[sta][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_for_compare\u001b[39m\u001b[38;5;124m'\u001b[39m], results[sta][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS_for_compare\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     83\u001b[0m pscore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p_score\n\u001b[1;32m     84\u001b[0m sscore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m s_score\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calculate_score' is not defined"
     ]
    }
   ],
   "source": [
    "# 目前还是没有做TTA的情况，因为上次的TTA示例代码是针对单个事件的，后面需要做针对多个事件的\n",
    "# Test-time augmentation\n",
    "\n",
    "score = 0\n",
    "pscore = 0\n",
    "sscore = 0\n",
    "P_dev_list = []\n",
    "S_dev_list = []\n",
    "ans_number=0\n",
    "res_number=0\n",
    "base_exam_path = '/home/disk/wd_black/wzm/Sustech_Pulse/test_data/%s-exam/T1/{}' %month\n",
    "out_dir = \"/home/disk/wd_black/wzm/Sustech_Pulse/src/finetune/zbk/dpk_output_%s.txt\" %month\n",
    "\n",
    "with open(out_dir,\"w\") as f:\n",
    "    f.write(\"i    P_answer   S_answer   P_predict   S_predict   \\n\")\n",
    "\n",
    "keys = list(answer_dict.keys())#[:1] \n",
    "for key in keys:\n",
    "    P_line = answer_dict[key][0]\n",
    "    if ';' in P_line:\n",
    "        P_answer_list = []\n",
    "        for t_split in P_line.split(';'):\n",
    "            P_answer_list.append(float(t_split))\n",
    "    else:\n",
    "        P_answer_list = [float(P_line)]\n",
    "    S_line = answer_dict[key][1]\n",
    "    if ';' in S_line:\n",
    "        S_answer_list = []\n",
    "        for t_split in S_line.split(';'):\n",
    "            S_answer_list.append(float(t_split))\n",
    "    else:\n",
    "        S_answer_list = [float(S_line)]\n",
    "\n",
    "    test_data = base_exam_path.format(key)\n",
    "    # print(test_data)\n",
    "    st = obspy.read(test_data, format=\"MSEED\", stream=True)\n",
    "    # st.detrend('demean') #去均值\n",
    "\n",
    "    # st.detrend('linear') #去趋势\n",
    "    # st.filter('bandpass',freqmin=0.005, freqmax=50.0) \n",
    "    \n",
    "    if st[0].stats.sampling_rate != 100.0:\n",
    "        st.resample(100.0)\n",
    "\n",
    "    results = {}\n",
    "    station_list = []\n",
    "    for tr in st:\n",
    "        station_list.append(tr.stats.station)\n",
    "    station_list = list(set(station_list))\n",
    "    for sta in station_list:\n",
    "        results[sta] = {}\n",
    "        results[sta]['P'] = []\n",
    "        results[sta]['S'] = []\n",
    "        results[sta]['P_for_compare'] = []\n",
    "        results[sta]['S_for_compare'] = []\n",
    "        \n",
    "        input_st = st.select(station=sta)\n",
    "        #对长的波形做multi event repeat (或者事件比较多，就走多事件的分支)\n",
    "        if input_st[0].stats.endtime - input_st[0].stats.starttime > 8*60:\n",
    "            input_st = input_st.filter('bandpass',freqmin=3, freqmax=50.0) \n",
    "            events = DiTing_EQDet_PhasePick_predict_fastV2_multievents(input_st, dpk_device, dpk_model, window_length=10000, step_size=3000, p_th=0.1, s_th=0.1, det_th=0.20, batch_size=100, max_repeat=7)\n",
    "        else:\n",
    "            input_st = input_st.detrend('demean')\n",
    "            events = DiTing_EQDet_PhasePick_predict_fastV2(input_st, dpk_device, dpk_model, window_length=10000, step_size=3000, p_th=0.1, s_th=0.1, det_th=0.30, batch_size=100, return_confidence=False)\n",
    "        for t_event in events:\n",
    "            try:\n",
    "                results[sta]['P'].append(str(input_st[0].stats.starttime + t_event[1][0][0]/100.0))\n",
    "                results[sta]['P_for_compare'].append( t_event[1][0][0]/100.0 )\n",
    "            except:\n",
    "                print(key,\"no P\")\n",
    "\n",
    "                pass\n",
    "            try:\n",
    "                results[sta]['S'].append(str(input_st[0].stats.starttime + t_event[2][0][0]/100.0))\n",
    "                results[sta]['S_for_compare'].append( t_event[2][0][0]/100.0 )\n",
    "            except:\n",
    "                print(key,\"no S\")\n",
    "                pass\n",
    "        with open(out_dir, \"a\") as f:\n",
    "            f.write(f\"{P_answer_list} {results[sta]['P_for_compare']} {S_answer_list} {results[sta]['S_for_compare']}\\n\")\n",
    "        p_score,s_score =calculate_score(P_answer_list, S_answer_list, results[sta]['P_for_compare'], results[sta]['S_for_compare'])\n",
    "\n",
    "        pscore += p_score\n",
    "        sscore += s_score\n",
    "        get_score=p_score+s_score\n",
    "        res_number +=len(results[sta]['P_for_compare'])+len(results[sta]['S_for_compare'])\n",
    "        ans_number +=len(P_answer_list)+len(S_answer_list)\n",
    "        #if get_score<len(P_answer_list)+len(S_answer_list)*0.9:\n",
    "        print(key,get_score, \"detect sum\" , len(results[sta]['P_for_compare'])+len(results[sta]['S_for_compare']) ,\"answer sum\",  len(P_answer_list)+len(S_answer_list) )\n",
    "\n",
    "            # st = input_st\n",
    "            # plt.figure(figsize=(24, 6))\n",
    "            # for tdx, tr in enumerate(st):\n",
    "            #     plt.subplot(len(st), 1, tdx + 1)\n",
    "            #     plt.plot(tr.times(), tr.data, color='k')\n",
    "            #     plt.title(tr.stats.station)\n",
    "\n",
    "            #     for filter_P in P_answer_list:\n",
    "            #         plt.axvline(x=input_st[0].stats.starttime + (np.mean(filter_P)), color='red', linestyle='--', label='P')\n",
    "            #     for filter_S in S_answer_list:\n",
    "            #         plt.axvline(x=input_st[0].stats.starttime + (np.mean(filter_S)), color='green', linestyle='--', label='S')\n",
    "            #     for GT_P in results[sta]['P_for_compare']:\n",
    "            #         plt.axvline(x=input_st[0].stats.starttime + GT_P, color='blue', linestyle=':', label='GT P')\n",
    "            #     for GT_S in results[sta]['S_for_compare']:\n",
    "            #         plt.axvline(x=input_st[0].stats.starttime + GT_S, color='orange', linestyle=':', label='GT S')\n",
    "            # plt.legend()\n",
    "            # plt.xlabel('Time (s)')\n",
    "            # plt.ylabel('Amplitude')\n",
    "            # plt.tight_layout()\n",
    "            # plt.suptitle(key+\" get:\"+str(get_score)+\"/\"+str( len(results[sta]['P_for_compare'])+len(results[sta]['P_for_compare']))+\" should: \"+str( len(P_answer_list)+len(S_answer_list)))\n",
    "            # plt.savefig(f\"/home/disk/wd_black/wzm/Sustech_Pulse/src/finetune/wzm/e10/{key}.png\")\n",
    "            # plt.close()\n",
    "            # plt.figure(figsize=(24, 6))\n",
    "            # for tdx, tr in enumerate(st):\n",
    "            #     plt.subplot(len(st), 1, tdx + 1)\n",
    "            #     plt.plot(tr.times(), tr.data, color='k')\n",
    "            #     plt.xlim(30, 33)\n",
    "            #     plt.title(tr.stats.station)\n",
    "            #     plt.axvline(x=input_st[0].stats.starttime + (np.mean(filter_P)), color='red', linestyle='--', label='P')\n",
    "            #     plt.axvline(x=input_st[0].stats.starttime + (np.mean(filter_S)), color='green', linestyle='--', label='S')\n",
    "            #     plt.axvline(x=input_st[0].stats.starttime + GT_P, color='blue', linestyle=':', label='GT P')\n",
    "            #     plt.axvline(x=input_st[0].stats.starttime + GT_S, color='orange', linestyle=':', label='GT S')\n",
    "\n",
    "            # plt.legend()\n",
    "            # plt.xlabel('Time (s)')\n",
    "            # plt.ylabel('Amplitude')\n",
    "            # plt.tight_layout()\n",
    "            # plt.show()\n",
    "\n",
    "\n",
    "    # print('cur score: {:.2f}'.format(score))\n",
    "score=pscore+sscore\n",
    "if res_number > ans_number* 1.05:  # 超过5%\n",
    "    score=pscore+sscore-math.ceil((res_number-ans_number*1.05))*0.5\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res_number)\n",
    "print(ans_number)\n",
    "print(pscore+sscore)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ditinglsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
